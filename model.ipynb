{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f70173a-0b22-4c79-a092-c10a1c09067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import io\n",
    "import zipfile\n",
    "from torchnet import meter\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms as T\n",
    "import io\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6f10ef96-30b8-46db-bf3e-7f2487512050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms as T\n",
    "import io\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "16ec3544-e377-4f35-a0b0-85608fdb61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cf65283a-c0c6-4ddc-a8be-2ec9d2f45d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1).cuda()\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1).cuda()\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1).cuda()\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1).cuda()\n",
    "        self.conv5 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1).cuda()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 20),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(20, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).cuda()\n",
    "        # (5120x128 and 160x20)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def save(self, name=None):\n",
    "        \"\"\"\n",
    "        save the model\n",
    "        \"\"\"\n",
    "        if name is None:\n",
    "            prefix = 'checkpoints/' + 'face_classifier_'\n",
    "            name = time.strftime(prefix + '%m%d_%H:%M:%S.pth')\n",
    "        torch.save(self.state_dict(), name)\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df7dca9-d80f-47fc-8a3b-e4dffbcd5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DEAP(data.Dataset):\n",
    "    '''\n",
    "    DEAP dataset for per-subject experiments\n",
    "\n",
    "    Parameters:\n",
    "        modal   : data modality; {'face', 'eeg', 'peri', 'bio', 'faceeeg', 'faceperi', 'facebio'}, default = 'facebio'.\n",
    "        subject : subject ID; an integer between 1 and 22, default = 1.\n",
    "        k       : kth fold; an integer between 1 and 10, default = 1.\n",
    "        kind    : dataset type; {'train', 'val', 'all'}, default = 'all'.\n",
    "        indices : index of data samples (for dataset shuffle); an list of integers, default = list(range(2400)).\n",
    "        label   : emotion label; {'valence', 'arousal'}, defualt = 'valence'.\n",
    "    '''\n",
    "    def __init__(self, modal='face', subject=1, k=1, kind='all', indices=list(range(2400)),label='valence'):\n",
    "        self.modal = modal\n",
    "        self.subject = subject\n",
    "        self.k = k\n",
    "        self.kind = kind\n",
    "        self.label = label\n",
    "        self.bio_path = f'./data/DEAP/bio/s{subject}.zip'\n",
    "        self.label_path = f'./data/DEAP/labels/'\n",
    "        self.face_path = f'./data/DEAP/faces/s{subject}.zip'\n",
    "        self.labels = pd.read_csv(self.label_path+'participant_ratings.csv')\n",
    "        # print(self.labels)\n",
    "        # uncomment\n",
    "        self.bio_zip = zipfile.ZipFile(self.bio_path, 'r')\n",
    "        # print(self.face_path)\n",
    "        self.face_zip = zipfile.ZipFile(self.face_path, 'r')\n",
    "        \n",
    "        \n",
    "        self.size = len(indices)\n",
    "\n",
    "        if kind == 'train':\n",
    "            self.indices = indices[:int((k - 1) * self.size / 10)] + indices[int(k * self.size / 10):]\n",
    "        if kind == 'val':\n",
    "            self.indices = indices[int((k - 1) * self.size / 10):int(k * self.size / 10)]\n",
    "        if kind == 'all':\n",
    "            self.indices = indices\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        index = self.indices[i]\n",
    "        trial = index // 60 + 1\n",
    "        segment = index % 60 + 1\n",
    "        prex = 's' + (str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '/s' + (\n",
    "            str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '_trial' + (\n",
    "                   str(trial) if trial > 9 else '0' + str(trial)) + '/s' + (\n",
    "                   str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '_trial' + (\n",
    "                   str(trial) if trial > 9 else '0' + str(trial))\n",
    "        transform = T.Compose([T.Resize((64, 64)),\n",
    "                               T.ToTensor()])\n",
    "\n",
    "        face_data = []\n",
    "        for n in range(1, 6):\n",
    "            # print(prex + f'_{(segment - 1) * 5 + n}.png')\n",
    "            try:\n",
    "                img = Image.open(io.BytesIO(self.face_zip.read(prex + f'_{(segment - 1) * 5 + n}.png')))\n",
    "\n",
    "                frame_array = transform(img)\n",
    "                frame_array = frame_array.view(1, 3, 64, 64)\n",
    "                face_data.append(frame_array)\n",
    "            except:\n",
    "                print(prex + f'_{(segment - 1) * 5 + n}.png' + \" file not exists in location\")\n",
    "            # print(prex + f'_{(segment - 1) * 5 + n}.png')\n",
    "\n",
    "        if len(face_data) == 0:\n",
    "            return None, None\n",
    "\n",
    "        while len(face_data) != 5:\n",
    "            face_data.append(face_data[0])\n",
    "\n",
    "        face_data = torch.cat(face_data, dim=0)\n",
    "\n",
    "\n",
    "        bio_data = torch.tensor(\n",
    "            np.load(io.BytesIO(self.bio_zip.read(f's{self.subject}/{self.subject}_{trial}_{segment}.npy')))).float()\n",
    "\n",
    "        if self.modal == 'face':\n",
    "            data = face_data\n",
    "        elif self.modal == 'eeg':\n",
    "            data = bio_data[:32]\n",
    "        \n",
    "\n",
    "        valence = 0 if self.labels[(self.labels['Participant_id']==self.subject) & (self.labels['Trial']==trial)]['Valence'].iloc[0] < 5 else 1\n",
    "        arousal = 0 if self.labels[(self.labels['Participant_id']==self.subject) & (self.labels['Trial']==trial)]['Arousal'].iloc[0] < 5 else 1\n",
    "       \n",
    "        if self.label == 'valence':\n",
    "            return data, valence\n",
    "        else:\n",
    "            return data, arousal\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "579beb4d-ba72-40b2-8f6c-aae13db6764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(lr = 0.001, batch_size = 32, epochs = 50, samples = 74040):\n",
    "\n",
    "    train_eeg = Deap(kind = \"train\", samples = samples)\n",
    "    test_eeg = Deap(kind = \"test\", samples = samples)\n",
    "\n",
    "    train_loader = DataLoader(train_eeg, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_eeg, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "\n",
    "    model = CNN_Model()\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    lr = lr \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    \n",
    "    #  creating a file results \n",
    "    try : \n",
    "        os.mkdir(\"./results\")\n",
    "    except Exception as E:\n",
    "        print(\"File results made\")\n",
    "    best_accuracy = 0\n",
    "\n",
    "    file_name = \"./results/result.txt\"\n",
    "    for epoch in range(epochs):\n",
    "        pred_label = []\n",
    "        true_label = []\n",
    "\n",
    "        loss_meter.reset()\n",
    "        for ii, (data, label) in enumerate(train_loader):\n",
    "        \n",
    "            input_ = data.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(input_).float()\n",
    "            pred = pred.squeeze().float()\n",
    "            # If there's only one element, enclose it in brackets, to be tensor of one-dimension\n",
    "            if pred.dim() == 0:\n",
    "                pred = pred.unsqueeze(0)\n",
    "\n",
    "            # print(pred, label, ii)\n",
    "            loss = criterion(pred, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # meters update\n",
    "            loss_meter.add(loss.item())\n",
    "\n",
    "            pred = (pred >= 0.5).float().to(device).data\n",
    "            pred_label.append(pred)\n",
    "            true_label.append(label)\n",
    "\n",
    "        pred_label = torch.cat(pred_label,0)\n",
    "        true_label = torch.cat(true_label,0)\n",
    "\n",
    "        print(epoch, torch.sum(pred_label == true_label), true_label.size(0))\n",
    "        train_accuracy = torch.sum(pred_label == true_label).type(torch.FloatTensor) / true_label.size(0)\n",
    "        out_put('Epoch: ' + 'train' + str(epoch) + '| train accuracy: ' + str(train_accuracy.item()), file_name)\n",
    "\n",
    "        val_accuracy = val(model, val_loader, use_gpu = True)\n",
    "        out_put('Epoch: ' + 'train' + str(epoch) + '| train loss: ' + str(loss_meter.value()[0]) +\n",
    "              '| val accuracy: ' + str(val_accuracy.item()), file_name)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_epoch = epoch\n",
    "            model.save(f\"{file_name}_best.pth\")\n",
    "\n",
    "    model.save(f'{file_name}.pth')\n",
    "\n",
    "    perf = f\"best accuracy is {best_accuracy} in epoch {best_epoch}\" + \"\\n\"\n",
    "    out_put(perf,file_name)\n",
    "\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9f9bc5a5-cf87-459f-8cb5-464ce3e81756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File results made\n",
      "0 tensor(33729, device='cuda:0') 59232\n",
      "tensor(8488, device='cuda:0') 14808\n",
      "1 tensor(35468, device='cuda:0') 59232\n",
      "tensor(9091, device='cuda:0') 14808\n",
      "2 tensor(37377, device='cuda:0') 59232\n",
      "tensor(9844, device='cuda:0') 14808\n",
      "3 tensor(39762, device='cuda:0') 59232\n",
      "tensor(10403, device='cuda:0') 14808\n",
      "4 tensor(41315, device='cuda:0') 59232\n",
      "tensor(10713, device='cuda:0') 14808\n",
      "5 tensor(42676, device='cuda:0') 59232\n",
      "tensor(11028, device='cuda:0') 14808\n",
      "6 tensor(43681, device='cuda:0') 59232\n",
      "tensor(11244, device='cuda:0') 14808\n",
      "7 tensor(44468, device='cuda:0') 59232\n",
      "tensor(11478, device='cuda:0') 14808\n",
      "8 tensor(45422, device='cuda:0') 59232\n",
      "tensor(11797, device='cuda:0') 14808\n",
      "9 tensor(46210, device='cuda:0') 59232\n",
      "tensor(11915, device='cuda:0') 14808\n",
      "10 tensor(46719, device='cuda:0') 59232\n",
      "tensor(12066, device='cuda:0') 14808\n",
      "11 tensor(47401, device='cuda:0') 59232\n",
      "tensor(12217, device='cuda:0') 14808\n",
      "12 tensor(47717, device='cuda:0') 59232\n",
      "tensor(12267, device='cuda:0') 14808\n",
      "13 tensor(48253, device='cuda:0') 59232\n",
      "tensor(12373, device='cuda:0') 14808\n",
      "14 tensor(48643, device='cuda:0') 59232\n",
      "tensor(12576, device='cuda:0') 14808\n",
      "15 tensor(48904, device='cuda:0') 59232\n",
      "tensor(12529, device='cuda:0') 14808\n",
      "16 tensor(49380, device='cuda:0') 59232\n",
      "tensor(12737, device='cuda:0') 14808\n",
      "17 tensor(49609, device='cuda:0') 59232\n",
      "tensor(12667, device='cuda:0') 14808\n",
      "18 tensor(49908, device='cuda:0') 59232\n",
      "tensor(12746, device='cuda:0') 14808\n",
      "19 tensor(50079, device='cuda:0') 59232\n",
      "tensor(12816, device='cuda:0') 14808\n",
      "20 tensor(50547, device='cuda:0') 59232\n",
      "tensor(12917, device='cuda:0') 14808\n",
      "21 tensor(50758, device='cuda:0') 59232\n",
      "tensor(12917, device='cuda:0') 14808\n",
      "22 tensor(50848, device='cuda:0') 59232\n",
      "tensor(13029, device='cuda:0') 14808\n",
      "23 tensor(51083, device='cuda:0') 59232\n",
      "tensor(13025, device='cuda:0') 14808\n",
      "24 tensor(51397, device='cuda:0') 59232\n",
      "tensor(12967, device='cuda:0') 14808\n",
      "25 tensor(51291, device='cuda:0') 59232\n",
      "tensor(13183, device='cuda:0') 14808\n",
      "26 tensor(51584, device='cuda:0') 59232\n",
      "tensor(13180, device='cuda:0') 14808\n",
      "27 tensor(51708, device='cuda:0') 59232\n",
      "tensor(13198, device='cuda:0') 14808\n",
      "28 tensor(51823, device='cuda:0') 59232\n",
      "tensor(13204, device='cuda:0') 14808\n",
      "29 tensor(52087, device='cuda:0') 59232\n",
      "tensor(13158, device='cuda:0') 14808\n",
      "30 tensor(52102, device='cuda:0') 59232\n",
      "tensor(13225, device='cuda:0') 14808\n",
      "31 tensor(52312, device='cuda:0') 59232\n",
      "tensor(13306, device='cuda:0') 14808\n",
      "32 tensor(52374, device='cuda:0') 59232\n",
      "tensor(13283, device='cuda:0') 14808\n",
      "33 tensor(52445, device='cuda:0') 59232\n",
      "tensor(13366, device='cuda:0') 14808\n",
      "34 tensor(52533, device='cuda:0') 59232\n",
      "tensor(13390, device='cuda:0') 14808\n",
      "35 tensor(52626, device='cuda:0') 59232\n",
      "tensor(13466, device='cuda:0') 14808\n",
      "36 tensor(52638, device='cuda:0') 59232\n",
      "tensor(13452, device='cuda:0') 14808\n",
      "37 tensor(52851, device='cuda:0') 59232\n",
      "tensor(13365, device='cuda:0') 14808\n",
      "38 tensor(52872, device='cuda:0') 59232\n",
      "tensor(13414, device='cuda:0') 14808\n",
      "39 tensor(52992, device='cuda:0') 59232\n",
      "tensor(13425, device='cuda:0') 14808\n",
      "40 tensor(53082, device='cuda:0') 59232\n",
      "tensor(13536, device='cuda:0') 14808\n",
      "41 tensor(53032, device='cuda:0') 59232\n",
      "tensor(13531, device='cuda:0') 14808\n",
      "42 tensor(53077, device='cuda:0') 59232\n",
      "tensor(13513, device='cuda:0') 14808\n",
      "43 tensor(53156, device='cuda:0') 59232\n",
      "tensor(13524, device='cuda:0') 14808\n",
      "44 tensor(53009, device='cuda:0') 59232\n",
      "tensor(13501, device='cuda:0') 14808\n",
      "45 tensor(53261, device='cuda:0') 59232\n",
      "tensor(13519, device='cuda:0') 14808\n",
      "46 tensor(53242, device='cuda:0') 59232\n",
      "tensor(13499, device='cuda:0') 14808\n",
      "47 tensor(53260, device='cuda:0') 59232\n",
      "tensor(13536, device='cuda:0') 14808\n",
      "48 tensor(53258, device='cuda:0') 59232\n",
      "tensor(13550, device='cuda:0') 14808\n",
      "49 tensor(53449, device='cuda:0') 59232\n",
      "tensor(13526, device='cuda:0') 14808\n"
     ]
    }
   ],
   "source": [
    "x = train_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "31e78d11-948c-4add-a9d9-43d9910da5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val(model, dataloader, use_gpu):\n",
    "    model.eval()\n",
    "    if use_gpu:\n",
    "      device = torch.device('cuda')\n",
    "    else:\n",
    "      device = torch.device('cpu')\n",
    "\n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "\n",
    "    for ii, (data, label) in enumerate(dataloader):\n",
    "        \n",
    "        input_ = data.float().to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(input_).float()\n",
    "\n",
    "        pred = (pred >= 0.5).float().to(device).data\n",
    "        pred = pred.squeeze().float()\n",
    "        \n",
    "        # If there's only one element, enclose it in brackets, to be tensor of one-dimension\n",
    "        if pred.dim() == 0:\n",
    "            pred = pred.unsqueeze(0)\n",
    "        pred_label.append(pred)\n",
    "        true_label.append(label)\n",
    "\n",
    "    # print(pred_label, len(pred_label))\n",
    "    # print(true_label,len(true_label))\n",
    "    pred_label = torch.cat(pred_label, 0)\n",
    "    true_label = torch.cat(true_label, 0)\n",
    "    \n",
    "    print(torch.sum(pred_label == true_label), true_label.size(0))\n",
    "    val_accuracy = torch.sum(pred_label == true_label).type(torch.FloatTensor) / true_label.size(0)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c6da8ddb-7bee-4d2c-8049-9553b01b19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_put(string, verbose):\n",
    "    '''\n",
    "    Help function for verbose,\n",
    "    output the string to destination path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string  :str,  the string to output\n",
    "    verbose :str, the path to store the output\n",
    "    '''\n",
    "    with open(f\"{verbose}.txt\", \"a\") as f:\n",
    "        f.write(string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddd178-89ee-4eaf-90d8-3844ef6ca500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
